{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Machine learning Handwritten Math Recognition</h1>\n",
    "After segmentation of a document has been completed, we will have a series of shapes which must be matched to a LaTex mathmode or ascii character, or a character representing blank which shall appear in the LaTeX but not be rendered in the pdf. Each shape will be paired with a position, and that position will be used to determine where to insert \"_{}\" or \"^{}\" based on rules. We will use a machine learning module that is multiclass and unilabel to learn the shapes as characters. The error will be measured by the minimum number of changes in character order (assume segmentation worked) where a change could include an insertion, a deletion, or a substitution, this is also known as the Levenshtein Distance (edit distance) of our document. We consider a character to be any LaTeX \"\\\\command\" or any ascii character. This LaTeX document will be compared to the original generated document and our algorithm will seek to minimize the Levenshtein Distance between the predicted and expected LaTeX character order.\n",
    "\n",
    "The list of supported characters was scraped from this page, which lists all mathematics symbols/characters\n",
    "\n",
    "https://oeis.org/wiki/List_of_LaTeX_mathematical_symbols\n",
    "\n",
    "All character commands except the trigonometric, hyperbolic, and those that produce the same symbol as another will be supported\n",
    "\n",
    "Levenshtein Distance L of a and b definition:\n",
    "https://www.python-course.eu/levenshtein_distance.php\n",
    "\n",
    "$if(min(i, j) = 0$ then \n",
    "$$lev_{a,b} = max(i, j)$$\n",
    "$else$\n",
    "$$lev_{a,b}(i,j) = min(lev_{a,b}(i - 1, j) + 1,lev_{a,b}(i, j + 1) + 1, lev_{a,b}(i - 1, j - 1) + 1_{\\{a_i \\neq b_j\\}} )$$\n",
    "$$L = lev_{a,b}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Successful\n",
      "Both Levenshtein tests were successful\n"
     ]
    }
   ],
   "source": [
    "#TODO: Segementation\n",
    "#TODO: Sample Generation with Hand (last step, since we can then compare this to not using Hand)\n",
    "#Complete: Sample Generation without Hand\n",
    "#Complete: Create function that takes Latex and turn it into a list of ordered characters with no formatting\n",
    "#TODO: Load Pretrained Neural Network\n",
    "#Complete: Levenshtein Distance\n",
    "\n",
    "#Assume Segmentation has already been completed.\n",
    "#Now I have a series of different sized character boxes for each shape. \n",
    "#Standardize shape by making all of them 56x56 numpy arrays of intensity\n",
    "import re\n",
    "import random\n",
    "import subprocess\n",
    "from scipy.misc import *\n",
    "import sys\n",
    "import warnings\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) #ignore imread deprecation warning\n",
    "\n",
    "\n",
    "random.seed(1111)\n",
    "\n",
    "with open('latexsymbols.txt', 'r') as f:\n",
    "    supported_characters = f.read().split('\\n')\n",
    "\n",
    "modify_level = [\"^\", \"_\", \"\\\\frac\", \" \", \"\\\\sqrt\"]\n",
    "\n",
    "def gen_random_latex(hand=False, name=\"rand0\", folder=\"./\"):\n",
    "    name = folder + name\n",
    "    latexheader = \"\"\"\n",
    "        \\\\documentclass[12pt]{article}\n",
    "        \\\\pagenumbering{gobble}\n",
    "        \\\\usepackage{amsmath}\n",
    "        \\\\usepackage{amssymb}\n",
    "        \\\\addtolength{\\\\topmargin}{-1.5in}\n",
    "        \\\\begin{document}\\n\n",
    "        \\\\begin{minipage}[t][0pt]{\\\\linewidth}\\n\n",
    "        \"\"\"\n",
    "    #generates one latex document with random values and levels\n",
    "    num_open = 0 \n",
    "    open_queue = 0 #add open bracket after next closing bracket if positive\n",
    "    body = \"\\\\[\"\n",
    "    linecontent = False #are all \\[ \\] full?\n",
    "    bracketcontent = False #are all {} full?\n",
    "    supportchar = \"\" #is there a space after the last support char, if the next char is not ^ or _\n",
    "    space = True #is the last character white space\n",
    "    charlast = True #was the last character ascii/support?\n",
    "    for i in range(350):\n",
    "        x = random.random()\n",
    "        if(num_open == 0 and open_queue == 0):\n",
    "            bracketcontent = False\n",
    "        if(x < .4 and num_open > 0 and bracketcontent): #If open bracket, close it 40ish% of the time\n",
    "            body += \"}\"\n",
    "            if(open_queue > 0):\n",
    "                body += \"{\"\n",
    "                open_queue -= 1\n",
    "            else:\n",
    "                num_open -= 1\n",
    "            charlast = False\n",
    "            bracketcontent = False\n",
    "        if(x < .01 and charlast and not space): # apparently ' is considered a superscript\n",
    "            c = \"'\"\n",
    "            charlast = False\n",
    "            bracketcontent = False\n",
    "        if(x < .09 and charlast and not space): #choose a ^ or _ or frac or space 5% of the time\n",
    "            c = random.choice(modify_level)\n",
    "            num_open += 1\n",
    "            body += c + \"{\"\n",
    "            if(c == \"\\\\frac\"):\n",
    "                open_queue += 1\n",
    "            if(c == \" \"):\n",
    "                space = True\n",
    "            else:\n",
    "                space = False\n",
    "            supportchar = \"\"\n",
    "            bracketcontent = False\n",
    "            charlast = False\n",
    "        elif(x < .3): #choose a supported character 35% of time\n",
    "            c = random.choice(supported_characters)\n",
    "            body += c\n",
    "            linecontent = True\n",
    "            if(num_open):\n",
    "                bracketcontent = True\n",
    "            supportchar = \" \"\n",
    "            space = False\n",
    "            charlast = True\n",
    "        elif(x < .38 and num_open == 0 and open_queue == 0 and linecontent): # new line 10ish% of time\n",
    "            body += \"\\\\]\\n\\\\[\"\n",
    "            linecontent = False\n",
    "            supportchar = \"\"\n",
    "            space = False\n",
    "            charlast = False\n",
    "            bracketcontent = False\n",
    "        else: #choose random ASCII on standard keyboard 50% of time\n",
    "            r = list(range(33, 123)) #keyboard values of ascii table\n",
    "            blacklist = [91,92,93,94,95,35,36,37,38, 39]\n",
    "            r = [x for x in r if x not in blacklist] #remove special characters and escape characters\n",
    "            n = random.choice(r)\n",
    "            c = chr(n)\n",
    "            body += supportchar + c #add a space before c if previous char is escaped\n",
    "            linecontent = True\n",
    "            space = False\n",
    "            charlast = True\n",
    "            if(num_open):\n",
    "                bracketcontent = True\n",
    "    while(num_open > 0): #If open bracket, close it 40ish% of the time\n",
    "            body += \" e}\"\n",
    "            if(open_queue > 0):\n",
    "                body += \"{r\"\n",
    "                open_queue -= 1\n",
    "            else:\n",
    "                num_open -= 1 \n",
    "    latexend = \"\"\"\n",
    "        \\\\]\\n\\\\end{minipage}\\n\\\\end{document}\n",
    "        \"\"\"\n",
    "    \n",
    "    #generate latex documents\n",
    "    latex_doc = latexheader + body + latexend\n",
    "    f = open(\"{}.tex\".format(name),\"w+\")\n",
    "    f.write(latex_doc)\n",
    "    f.close()\n",
    "    return latex_doc\n",
    "\n",
    "def get_latex_img(name, folder=\"./\"):\n",
    "    name = folder + name\n",
    "    #compile latex documents\n",
    "    #dependency: texlive; bash\n",
    "    subprocess.check_output(['pdflatex', \"-output-directory=\" + folder,  '{}.tex'.format(name)])\n",
    "    #convert pdfs to images jpg\n",
    "    #dependency: ImageMagick; bash\n",
    "    subprocess.check_output(['convert', '-quality', '100',  '{}.pdf'.format(name), '{}.jpg'.format(name)])\n",
    "    #now we need to read the images in as arrays and segment them into 28x28px arrays consisting of all the black squares.\n",
    "    #dependency: Scipy\n",
    "    img = imread(\"{}.jpg\".format(name), mode=\"L\")/255 #read in latex doc as image\n",
    "    return img\n",
    "def generate_samples(num, hand=False, folder=\"./\", nm=\"rand\"):\n",
    "    '''generates num latex docs and returns the set of images'''\n",
    "    imgs = []\n",
    "    for i in range(num):\n",
    "        name = nm + str(i)\n",
    "        gen_random_latex(hand, name=name, folder=folder)\n",
    "        img = np.round(get_latex_img(name, folder=folder))\n",
    "        imgs.append(img)\n",
    "    return imgs\n",
    "    \n",
    "def simplify(latex, verbose=0):\n",
    "    '''Returns a list containing each character in a LaTex document string in order of appearance'''\n",
    "    start = latex.find(\"\\\\begin{document}\") + len(\"\\begin{document}\")\n",
    "    end = latex.find(\"\\\\end{document}\")\n",
    "    latex = latex[start: end] #document body\n",
    "    latex = latex.replace(\"\\\\[\",\"\") #removing noncharacter command for equations\n",
    "    latex = latex.replace(\"\\\\]\",\"\") #removing noncharacter command for equations\n",
    "    latex = latex.replace(\"\\n\", \"\")\n",
    "    #latex = latex.replace(\"$\", \"\") #removing noncharacter command for equations\n",
    "    #latex = latex.replace(\"\\text{\") should make a function for this if necessary later on\n",
    "    #find all supported LaTeX commands\n",
    "    escaped_chars = [re.escape(x) for x in supported_characters]\n",
    "    found_symbols = re.findall(r\"(?=(\"+'|'.join(escaped_chars)+r\"))\", latex)\n",
    "    found_symbols = list(filter(None, found_symbols)) #remove empty strings    \n",
    "    #search latex file. For every \"\\\" add the next found supported word to a list, then remove its first occurence from the string and list\n",
    "    arr = []\n",
    "    if(verbose): print(found_symbols)\n",
    "    for c in latex:\n",
    "        try:\n",
    "            if(c == \"\\\\\"): #found a \"\\\" command\n",
    "                sym = found_symbols.pop(0)\n",
    "                arr.append(sym)\n",
    "                latex = latex.replace(sym, \"\", 1)\n",
    "            elif(c in \"{}^_\" ): #found a position delimeter or container that doesn't belong to a command\n",
    "                pass\n",
    "            else: #found a normal character\n",
    "                arr.append(c)\n",
    "        except IndexError:\n",
    "            if(verbose): print(\"Warning no symbols remaining\")\n",
    "    return arr\n",
    "class lev:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def Levenshtein(self, observed, expected, simplify = False):\n",
    "        '''Determines the Levenshtein distance between the ordered lists; Uses Memoization'''\n",
    "        if(simplify):\n",
    "            a = simplify(observed)\n",
    "            b = simplify(expected)\n",
    "        else:\n",
    "            a = observed\n",
    "            b = expected\n",
    "        self.M = np.array([[-1]*(len(b)+1)]*(len(a)+1))\n",
    "        return self.levenhelper(a, b, len(a), len(b) )\n",
    "\n",
    "    def levenhelper(self, a, b, i, j):\n",
    "        '''for recursive levenshtein distance dynamic programming\n",
    "        ***Gives the distance between the first i characters of a and the first j characters of b.\n",
    "        '''\n",
    "        if(i == 0 or j == 0 or j > len(b) or i > len(a)):\n",
    "                return max(i,j)\n",
    "        elif(self.M[i,j] != -1):\n",
    "            return self.M[i,j]\n",
    "        else:\n",
    "            self.M[i,j] = min([\n",
    "                self.levenhelper(a, b, i - 1, j) + 1,\n",
    "                self.levenhelper(a, b, i, j + 1) + 1,\n",
    "                self.levenhelper(a, b, i-1, j-1) + (a[i - 1] != b[j - 1])\n",
    "            ])\n",
    "            return self.M[i,j]\n",
    "LEV = lev()\n",
    "def test(function, verbose=True):\n",
    "    '''Used to test the various function implementations before proceeding with the project'''\n",
    "    if(function == \"gen_random_latex\"):\n",
    "        try: #if this throws an error, the latex did not successfully compile, otherwise, it was successful\n",
    "            gen_random_latex()\n",
    "            if(verbose): \n",
    "                print(\"Test Successful\")\n",
    "        except:\n",
    "            if(verbose):\n",
    "                print(\"Test Failed\")\n",
    "                print(sys.exc_info()[0])\n",
    "    if(function == \"simplify\"):\n",
    "        gen_random_latex()\n",
    "        with open(\"rand0.tex\") as f:\n",
    "            l = f.read().replace(\"\\n\",\"\")\n",
    "        if(verbose):\n",
    "            print(\"Compare the following result to the latex file to test\")\n",
    "            print(simplify(l))\n",
    "    if(function == \"Levenshtein\"):\n",
    "        arr1 = [\"1\", \"3\", \"2\", \"5\", \"10\"]\n",
    "        arr2 = [\"1\", \"2\", \"9\" ]\n",
    "        bul2 = LEV.Levenshtein(arr1,arr2) == 3\n",
    "        arr1 = [\"11\", \"3\", \"2\", \"5\", \"10\"]\n",
    "        arr2 = [\"1\", \"2\", \"9\", \"5\", \"5\", \"6\" ]\n",
    "        bul1 = LEV.Levenshtein(arr1,arr2) == 5\n",
    "        if(verbose):\n",
    "            if(bul1 and bul2):\n",
    "                print(\"Both Levenshtein tests were successful\")\n",
    "            else:\n",
    "                print(\"One or more tests were unsuccessful\")\n",
    "    if(function == \"generate_samples\"):\n",
    "        if(verbose):\n",
    "            print(generate_samples(20)[0])\n",
    "def clear_dir(dir = \"./\"):\n",
    "    '''Removes jpg, log, aux, and tex files from directory'''\n",
    "    try:\n",
    "        os.system(\"rm  {0}*.tex {0}*.aux {0}*.log {0}*.jpg {0}*.pdf\".format(dir))\n",
    "        #if(dir != \"./\"):\n",
    "    except Exception as e: print(e)\n",
    "\n",
    "#clear_dir()        \n",
    "test(\"gen_random_latex\")\n",
    "test(\"Levenshtein\")\n",
    "test(\"simplify\", verbose= False)\n",
    "test(\"generate_samples\", verbose = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paper which discusses the 2D method of considering structure before symbol makes 4 different classifications based on a symbols location with respect to other symbols. Above, superscript, inline, subscript, and below. But in LaTeX there isn't a distinction between above and superscript or below and subscript, as they are each coded with \"^\" and \"_\" respectively. I propose a modification to the method which considers the line on 3 levels rather than 5. Inline, superscript, and subscript.I intend to base my segmentation method off of this paper because they had a very high accuracy in that regard, but they had poor symbol recognition, so I choose to modify their methods significantly to achieve better results.\n",
    "\n",
    "1) Take the image, convert to bounding boxes\n",
    "2) classify these bounding boxes as inline, subscript, superscript, and unknown using small neural network.\n",
    "3) classify the symbols in each box using large multiclassification neural network.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#0 == black\n",
    "def find_connected(img, i,j, black): #issue: takes extraneous amount of time and can't see whole characters\n",
    "    '''recursively generates list of all neighbors of i and j, black is a set'''\n",
    "    #print(i,j)\n",
    "    if((0 < i < img.shape[0] and 0 < j < img.shape[1])): \n",
    "        \n",
    "        if(img[i,j] < 1 and (i,j) not in black):\n",
    "            #print(i,j)\n",
    "            black.add((i,j))\n",
    "            #check cardinal directions, as all others will be recursively detected   \n",
    "            return find_connected(img, i, j+1, black) | find_connected(img, i+1, j, black) \\\n",
    "                | find_connected(img, i, j-1, black) | find_connected(img, i-1, j, black)\n",
    "    return black\n",
    "    \n",
    "def find_connected2(img, i, j, black): #issue takes a lot of time and cant see whole characters\n",
    "    BOUND = 28 #assume a character is within a BOUND x BOUND array\n",
    "    if((max(0, i - BOUND) < i < min(img.shape[0], i + BOUND)) and (max(0, j - BOUND) < j < min(img.shape[1], j + BOUND))): \n",
    "        if(img[i,j] < 1 and (i,j) not in black):\n",
    "            #print(i,j)\n",
    "            black.add((i,j))\n",
    "            #check cardinal directions, as all others will be recursively detected   \n",
    "            return find_connected(img, i, j+1, black) | find_connected(img, i+1, j, black) \\\n",
    "                | find_connected(img, i, j-1, black) | find_connected(img, i-1, j, black)\n",
    "    return black\n",
    "    \n",
    "def find_connected3(img, i, j, component_num, components):\n",
    "    if(img[i,j] < 1 and components[i,j] == 0):\n",
    "        components[i,j] = component_num \n",
    "    if(img[i,j] < 1):\n",
    "        if(img[i, j+1] < 1): components[i,j] = component_num\n",
    "def get_bounding_boxes2(img, plot= False):\n",
    "    #this algorithm is based on the one from appendix B of the dissertation\n",
    "    labels = np.zeros(img.shape, dtype = np.int16)\n",
    "    eq_table = [0]\n",
    "    currentlabel = 0\n",
    "    used_labels = [False]\n",
    "\n",
    "    #first pass through\n",
    "    for i in range(1, img.shape[0] - 1):\n",
    "        for j in range(1, img.shape[1] - 1):\n",
    "            if(img[i,j] < 1):\n",
    "                neigh = [0]*4\n",
    "                nbnei = 0;\n",
    "                if(labels[i - 1][j] > 0):    \n",
    "                    neigh[nbnei] = labels[i - 1][j]\n",
    "                    nbnei += 1\n",
    "                if(labels[i+1][j] > 0):\n",
    "                    neigh[nbnei] = labels[i + 1][j]\n",
    "                    nbnei += 1\n",
    "                if(labels[i][j+1] > 0):\n",
    "                    neigh[nbnei] = labels[i][j + 1]\n",
    "                    nbnei += 1\n",
    "                if(labels[i][j-1] > 0):\n",
    "                    neigh[nbnei] = labels[i][j - 1]\n",
    "                    nbnei += 1\n",
    "                if(nbnei == 0): #create new label\n",
    "                    currentlabel += 1\n",
    "                    eq_table.append(currentlabel)\n",
    "                    used_labels.append(False)\n",
    "                    labels[i][j] = currentlabel\n",
    "                else:\n",
    "                    minlabel = img.shape[0] * img.shape[1]\n",
    "                    for i in range(nbnei):\n",
    "                        if(neigh[i] < minlabel):\n",
    "                            minlabel = eq_table[neigh[i]]\n",
    "                    labels[i][j] = eq_table[minlabel]\n",
    "                    for i in range(nbnei):\n",
    "                        if(eq_table[neigh[i]] > minlabel):\n",
    "                            eq_table[neigh[i]] = eq_table[minlabel]\n",
    "                            \n",
    "    for i in range(len(eq_table)):\n",
    "        if(eq_table[i] > eq_table[eq_table[i]]):\n",
    "            eq_table[i] = eq_table[eq_table[i]]\n",
    "            \n",
    "    #second pass through\n",
    "    bounding_boxes = np.zeros((currentlabel + 1, 4), dtype = np.int16)\n",
    "    newlab = -1\n",
    "    for i in range(1, img.shape[0] - 1):\n",
    "        for j in range(1, img.shape[1] - 1):\n",
    "            if(labels[i,j] > 0):\n",
    "                newlab = eq_table[labels[i,j]]\n",
    "                if(used_labels[newlab]): #update bounding box\n",
    "                    if(bounding_boxes[newlab][ 0 ] > i): bounding_boxes[newlab][0] = i\n",
    "                    elif(bounding_boxes[newlab][1] < i): bounding_boxes[newlab][1] = i\n",
    "                    if(bounding_boxes[newlab][ 2 ] > j): bounding_boxes[newlab][2] = j\n",
    "                    elif(bounding_boxes[newlab][3] < j): bounding_boxes[newlab][3] = j\n",
    "                \n",
    "                else:\n",
    "                    used_labels[newlab] = True\n",
    "                    bounding_boxes[newlab][0],bounding_boxes[newlab][1] = i,i\n",
    "                    bounding_boxes[newlab][2],bounding_boxes[newlab][3] = j,j\n",
    "\n",
    "    if(plot):\n",
    "        for quad in bounding_boxes:\n",
    "            mini,maxi,minj,maxj = quad\n",
    "            img[mini:maxi, minj:maxj] = 0\n",
    "        imsave(\"boxed.jpg\",img)\n",
    "        plt.imshow(img, cmap=plt.get_cmap('Greys_r'), aspect = \"auto\")\n",
    "        plt.show()\n",
    "    return bounding_boxes\n",
    "    \n",
    "                \n",
    "def get_bounding_boxes(img, plot = False):\n",
    "    '''labels each connected component in the img, then finds the bounding box for that component'''\n",
    "    '''We want to find all indices that communicate with i and j and add them to the same component'''\n",
    "    if(plot):\n",
    "        imsave(\"og.jpg\",img)\n",
    "    labels = []\n",
    "    lowest = 0\n",
    "    #print(img.shape)\n",
    "    #print(img)\n",
    "    #print(\"searching for components\")\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            #detecting connected components\n",
    "            #print(lowest)\n",
    "            pairs = np.array(labels).flatten()\n",
    "            if(img[i,j] < 1 and (i,j) not in pairs): #if component black find its neighbors\n",
    "                #print(\"found a component\")\n",
    "                black = set()\n",
    "                conn = find_connected2(img, i,j, black)\n",
    "                labels.append(conn)\n",
    "    \n",
    "    \n",
    "    \n",
    "    bounding_boxes = set()\n",
    "    #print(labels)\n",
    "    for component in labels:\n",
    "        #print(component)\n",
    "        mini = img.shape[0] #find all four values in one pass through the component\n",
    "        minj = img.shape[1]\n",
    "        maxi = 0\n",
    "        maxj = 0\n",
    "        for pair in component:\n",
    "            if(pair[0] < mini): mini = pair[0]\n",
    "            if(pair[0] > maxi): maxi = pair[0]\n",
    "            if(pair[1] < minj): minj = pair[1]\n",
    "            if(pair[1] > maxj): maxj = pair[1]\n",
    "        bounding_boxes.add((mini, maxi, minj, maxj))\n",
    "        img2 = img.copy()\n",
    "        img2[mini:maxi, minj:maxj] = 0 #drawing black box over character\n",
    "    #print(\"Preparing to plot bounding boxes\")\n",
    "    if(plot):\n",
    "        imsave(\"boxed.jpg\",img2)\n",
    "        plt.imshow(img2, cmap=plt.get_cmap('Greys_r'), aspect = \"auto\")\n",
    "        plt.show()\n",
    "    return list(bounding_boxes)\n",
    "#boxes = get_bounding_boxes(generate_samples(1)[0], plot=0)\n",
    "#chars = []\n",
    "#for box in boxes:\n",
    "#    mini,maxi,minj,maxj = box\n",
    "#    chars.append(imresize(img[mini:maxi, minj:maxj]), (56,56)) #resizes all images to 56x56 for ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Preprocessing and Generating Samples For Training and Testing</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_size = 30\n",
    "test_size = 15\n",
    "from skimage import io, filters\n",
    "\n",
    "\n",
    "def preprocess(generate = False):\n",
    "    if(generate): #if this is False, the samples have been generated\n",
    "        clear_dir(\"./train/\")\n",
    "        clear_dir(\"./test/\")\n",
    "        train_samples = generate_samples(train_size, folder = \"./train/\", nm=\"\")\n",
    "        test_samples = generate_samples(test_size, folder = \"./test/\", nm=\"\")\n",
    "    else:\n",
    "        train_samples = [imread(os.path.join(\"./train\", x)) for x in os.listdir(\"./train/\") if x[-4:] == \".jpg\"]\n",
    "        test_samples = [imread(os.path.join(\"./test\", x)) for x in os.listdir(\"./test/\") if x[-4:] == \".jpg\"]\n",
    "        \n",
    "    #preprocessing\n",
    "    for i in range(train_size):\n",
    "        dir = './train/{}'.format(i)\n",
    "        try:\n",
    "            os.system(\"rm -r \" + dir)\n",
    "            os.system(\"mkdir  {}\".format(dir))\n",
    "        except Exception as e: print(e)\n",
    "        \n",
    "        img = train_samples[i]    \n",
    "        boxes = get_bounding_boxes(train_samples[i])\n",
    "        subdir = dir + '/{}'.format(len(boxes)) \n",
    "        j = 0\n",
    "        for box in boxes:\n",
    "            mini,maxi,minj,maxj = box\n",
    "            image = img[mini:maxi+1, minj:maxj+1]\n",
    "            #image = filters.gaussian(image, 5)\n",
    "            #image = imresize(image, (56,56))\n",
    "            if(image.shape[0] > 3 and image.shape[1] > 3):\n",
    "                imsave(subdir + \"{}.jpg\".format(j), image)\n",
    "            j += 1\n",
    "\n",
    "    for i in range(test_size):\n",
    "        dir = './test/{}'.format(i)    \n",
    "        try:\n",
    "            os.system(\"rm -r\" + dir)\n",
    "            os.system(\"mkdir  {}\".format(dir))\n",
    "        except Exception as e: print(e)\n",
    "        img = test_samples[i]\n",
    "        boxes = get_bounding_boxes(test_samples[i])\n",
    "        subdir = dir + '/{}'.format(len(boxes)) \n",
    "        j = 0\n",
    "        for box in boxes:\n",
    "            mini,maxi,minj,maxj = box\n",
    "            image = img[mini:maxi+1, minj:maxj+1]\n",
    "            #image = filters.gaussian(image, 5)\n",
    "            #image = imresize(image, (299, 299))\n",
    "            if(image.shape[0] > 3 and image.shape[1] > 3):\n",
    "                imsave(subdir + \"{}.jpg\".format(j), image)\n",
    "            j += 1\n",
    "if(1):\n",
    "    preprocess(generate=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>CNN</h1>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from torch.utils.data import *\n",
    "from skimage import io, transform\n",
    "import scipy.ndimage as sci\n",
    "plt.ion()\n",
    "\n",
    "\n",
    "#image processing\n",
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "        h, w = image.shape[:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        img = transform.resize(image, (new_h, new_w))\n",
    "\n",
    "        return {'image': img, 'label': label}\n",
    "\n",
    "\n",
    "class RandomCrop(object):\n",
    "    \"\"\"Crop randomly the image in a sample.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = self.output_size\n",
    "\n",
    "        top = np.random.randint(0, h - new_h)\n",
    "        left = np.random.randint(0, w - new_w)\n",
    "\n",
    "        image = image[top: top + new_h,\n",
    "                      left: left + new_w]\n",
    "        return {'image': image, 'label': label}\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        \n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return (torch.from_numpy(image),\n",
    "                torch.from_numpy(label))\n",
    "\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        Rescale(256),\n",
    "        RandomCrop(224),\n",
    "        ToTensor()\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        Rescale(256),\n",
    "        RandomCrop(224),\n",
    "        ToTensor()\n",
    "    ])\n",
    "}\n",
    "\n",
    "\n",
    "def get_indices(root_dir, datafolder):\n",
    "    sizes = []\n",
    "    path = os.path.join(root_dir, datafolder)\n",
    "    for batch in sorted(os.listdir(path)):\n",
    "        path2 = os.path.join(path, batch)\n",
    "        if(os.path.isdir(path2)):\n",
    "            x = subprocess.check_output(['ls','-l', '{}'.format(path2)])\n",
    "            x = len(x.splitlines()) - 1\n",
    "            sizes.append(x)\n",
    "    cum_sizes = [0] * len(sizes)\n",
    "    for i in range(len(sizes)):\n",
    "        for j in range(i+1):\n",
    "            cum_sizes[i] += sizes[j]\n",
    "    indices = [0]*len(sizes)\n",
    "    for i in range(len(indices)):\n",
    "        if(i - 1 < 0):\n",
    "            indices[i] = list(range(cum_sizes[i]))\n",
    "        else:\n",
    "            indices[i] = list(range(cum_sizes[i-1],cum_sizes[i]))\n",
    "    return indices\n",
    "    \n",
    "    \n",
    "get_indices(\"./\", \"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "r = list(range(33, 123)) #keyboard values of ascii table\n",
    "blacklist = [92,94,95,35,36,37,38, 39]\n",
    "r = [chr(x) for x in r if x not in blacklist] #remove special characters and escape characters\n",
    "class_names = r + supported_characters + [' ', \"#\", \"$\", \"&\"]\n",
    "#print(class_names)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class BatchSampler(torch.utils.data.sampler.BatchSampler):\n",
    "    def __init__(self, folder, batch_size=0, drop_last=False):\n",
    "        '''if not isinstance(sampler, torch.utils.data.sampler.SequentialSampler):\n",
    "            raise ValueError(\"sampler should be an instance of \"\n",
    "                             \"torch.utils.data.SequentialSampler, but got sampler={}\"\n",
    "                             .format(sampler))\n",
    "        \n",
    "        if not isinstance(batch_size, _int_classes) or isinstance(batch_size, bool) or \\\n",
    "                batch_size <= 0:\n",
    "            raise ValueError(\"batch_size should be a positive integeral value, \"\n",
    "                             \"but got batch_size={}\".format(batch_size))\n",
    "        if not isinstance(drop_last, bool):\n",
    "            raise ValueError(\"drop_last should be a boolean value, but got \"\n",
    "                             \"drop_last={}\".format(drop_last))\n",
    "        '''\n",
    "        self.batch_size = batch_size\n",
    "        self.drop_last = drop_last\n",
    "        self.currentbatch = 0\n",
    "        self.batches = get_indices(\"./\", folder)\n",
    "    def __iter__(self):\n",
    "        #if(self.currentbatch < len(self.batches)):\n",
    "        #    yield self.batches[self.currentbatch]\n",
    "        #self.currentbatch += 1\n",
    "        return iter(self.batches)\n",
    "    def __len__(self):\n",
    "        return len(self.batches)\n",
    "\n",
    "class SymbDataset(Dataset):\n",
    "    \"\"\"Dataset Class For CNN\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, classnames=None, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory containing all of the images and tex files.\n",
    "            classnames (list): List of all of the possible classes\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.len = None #calculate length only once\n",
    "        self.classnames = classnames\n",
    "        self.docs = []\n",
    "        for file in os.listdir(root_dir):\n",
    "            #print(file)\n",
    "            if file.endswith(\".tex\"):\n",
    "                path = os.path.join(root_dir, file)\n",
    "                with open(path, 'r') as f:\n",
    "                    self.docs.append( (  file , simplify(f.read(), 0) ) ) #tup containing file, expected result values pairs\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        #print(self.docs)\n",
    "\n",
    "    def __len__(self): #returns number of images\n",
    "        path = self.root_dir\n",
    "        tot = get_indices(\"./\", path)[-1][-1]\n",
    "        self.len = tot\n",
    "        return tot\n",
    "\n",
    "    def len2(self): #returns number of batches\n",
    "        return len(self.docs)\n",
    "    def get_idx(self, idx):\n",
    "        #finds the batch number given an index of all the images\n",
    "        batch = 0\n",
    "        cum = 0\n",
    "        l=0\n",
    "        while(idx > 0):\n",
    "            path = os.path.join(self.root_dir, str(batch))\n",
    "            l = len(os.listdir(path))\n",
    "            if(idx >= l): \n",
    "                batch += 1\n",
    "                idx -= l\n",
    "                cum +=l\n",
    "            else: break\n",
    "\n",
    "        self.idx1 = batch\n",
    "        self.idx2 = idx\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        self.get_idx(idx)\n",
    "        idx1 = self.idx1\n",
    "        idx2 = self.idx2\n",
    "        imglabel = self.docs[idx1][1] #label with file contents\n",
    "        #print(imglabel)\n",
    "        imglabel = np.array([self.classnames.index(classname) for classname in imglabel]) #array with the indices for each class in classnames\n",
    "        #print(imglabel)\n",
    "\n",
    "\n",
    "        imgdir = os.path.join(self.root_dir, self.docs[idx1][0].strip(\".tex\"))\n",
    "        img = None\n",
    "        l = idx2\n",
    "        \n",
    "        for file in sorted(os.listdir(imgdir)):\n",
    "            file = os.path.join(imgdir, file)\n",
    "            #print(file)\n",
    "            if(l == 0):\n",
    "                img = sci.imread(file, mode=\"RGB\")\n",
    "                if(img is None):\n",
    "                    return __getitem__(idx+1)\n",
    "                                 \n",
    "            l -= 1\n",
    "        #sample = np.array((img , imglabel))\n",
    "        #print(img.shape, imglabel.shape)\n",
    "        sample = {'image': img, 'label': imglabel}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "        \n",
    "data_dir = \"./\"\n",
    "\n",
    "image_datasets = {x: SymbDataset(os.path.join(data_dir, x), classnames = class_names ,\n",
    "                                          transform = data_transforms[x])\n",
    "                  for x in ['train', 'test']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_sampler = BatchSampler(\"./\", x),\n",
    "                                              num_workers=0) \n",
    "              for x in ['train', 'test']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    \n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "#print(repr(inputs), repr(classes))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "imshow(out)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "class LevenshteinDist(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LevenshteinLoss, self).__init__()\n",
    "    def forward(self, outputs, labels):\n",
    "        return levenshtein_dist(outputs, labels)\n",
    "\n",
    "def levenshtein_dist(pred, targets):\n",
    "    '''preds are arrays of size classes with floats in them'''\n",
    "    '''targets are arrays of all the classes from the batch'''\n",
    "    '''we return the edit distance / length'''\n",
    "    #pred = [class_names[x] for x in pred]\n",
    "    return LEV.Levenshtein(pred, targets, simplify=False)\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=15):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_lev_dist = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            batches = 0\n",
    "            avg_lev_Dist = 0\n",
    "            # Iterate over data.\n",
    "            print(\"about to iterate over dataloader\")\n",
    "            for data in dataloaders[phase]:\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "                inputs = inputs.float()\n",
    "                #print(inputs, labels)\n",
    "                \n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "                    inputs = Variable(inputs.cuda())\n",
    "                    labels = Variable(labels.cuda())\n",
    "                else:\n",
    "                    inputs = Variable(inputs)\n",
    "                    labels = Variable(labels)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                #print(inputs)\n",
    "                # forward\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                #outputs = nn.functional.sigmoid(outputs)\n",
    "                _, preds = torch.max(outputs, 1) \n",
    "                label = labels.diag().long()\n",
    "                                \n",
    "                #print(labels.shape)\n",
    "                #print(pred.shape)\n",
    "                \n",
    "                loss = criterion(outputs, label)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    #print(\"backward step of training phase\")\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    #print(\"Optimizer adjusted\")\n",
    "\n",
    "                # statistics\n",
    "                #print(\"calculating order statistics\")\n",
    "                running_loss += loss.data[0] * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds.data == label.data)\n",
    "                avg_lev_Dist += levenshtein_dist(preds.data, label.data)\n",
    "                \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "            epoch_lev_dist = avg_lev_Dist / dataset_sizes[phase]\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'test' and epoch_lev_dist < best_lev_dist:\n",
    "                #print(\"deepcopying model\")\n",
    "                best_acc = epoch_acc\n",
    "                best_lev_dist = epoch_lev_dist\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    print('Best val Levenshtein Distance: {}'.format(best_lev_dist))\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "model_ft.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "if use_gpu:\n",
    "    model_ft = model_ft.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=2)\n",
    "\n",
    "def visualize_model(model, num_images=9):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    for i, data in enumerate(dataloaders['test']):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.float()\n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        __, preds = torch.max(outputs, 1) \n",
    "        #preds = nn.functional.sigmoid(preds).round()\n",
    "        labels = labels.diag()\n",
    "                \n",
    "        for j in range(inputs.size()[0]):\n",
    "            images_so_far += 1\n",
    "            ax = plt.subplot(num_images//3, 3, images_so_far)\n",
    "            ax.axis('off')\n",
    "            #print(preds,j)\n",
    "            ax.set_title('predicted: {}'.format(class_names[int(preds.data[j])]))\n",
    "            imshow(inputs.cpu().data[j])\n",
    "\n",
    "            if images_so_far == num_images:\n",
    "                model.train(mode=was_training)\n",
    "                return\n",
    "    model.train(mode=was_training)\n",
    "print(\"visualizing model\")\n",
    "visualize_model(model_ft)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
